{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3d3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Flow for Flipkart Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a558dc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f1271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d94fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21023d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5880a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df756b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885996d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee986cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76775138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Reviewer Name               Review Title  \\\n",
       "0               Kamal Suresh               Nice product   \n",
       "1          Flipkart Customer     Don't waste your money   \n",
       "2     A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3        Suresh Narayanasamy                       Fair   \n",
       "4                  ASHIK P A                Over priced   \n",
       "...                      ...                        ...   \n",
       "8513                     NaN                        NaN   \n",
       "8514                     NaN                        NaN   \n",
       "8515                     NaN                        NaN   \n",
       "8516                     NaN                        NaN   \n",
       "8517                     NaN                        NaN   \n",
       "\n",
       "                  Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0      Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1      Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2     Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3        Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                             NaN     147.0        24.0  Apr 2016   \n",
       "...                           ...       ...         ...       ...   \n",
       "8513                          NaN       NaN         NaN       NaN   \n",
       "8514                          NaN       NaN         NaN       NaN   \n",
       "8515                          NaN       NaN         NaN       NaN   \n",
       "8516                          NaN       NaN         NaN       NaN   \n",
       "8517                          NaN       NaN         NaN       NaN   \n",
       "\n",
       "                                            Review text  Ratings  \n",
       "0     Nice product, good quality, but price is now r...        4  \n",
       "1     They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2     Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3     Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4     Over pricedJust â?¹620 ..from retailer.I didn'...        1  \n",
       "...                                                 ...      ...  \n",
       "8513                                                NaN        5  \n",
       "8514                                                NaN        2  \n",
       "8515                                                NaN        4  \n",
       "8516                                                NaN        1  \n",
       "8517                                                NaN        4  \n",
       "\n",
       "[8518 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Badminton = pd.read_csv(\"data.csv\")\n",
    "Badminton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07c69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa54bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20cf81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Badminton.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5d8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10aa3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e07d904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Badminton.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16123bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a2a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Badminton.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095e8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb6e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify reviews as positive or negative based on ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d85a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(rating):\n",
    "    if rating >= 3.0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31ea6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Badminton['Sentiment'] = Badminton['Ratings'].apply(classify_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e110156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e2293eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b53a49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Badminton['Review text']\n",
    "\n",
    "y = Badminton['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cce287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99d966f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41be519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84a8a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "130fea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6410,) (1603,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 1)\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0fb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9024fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing on Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0962fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8f31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05eee497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring 'Stemming' and 'Lemmatization' variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed8e26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemming = PorterStemmer()\n",
    "Lemmatization = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d49551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5831f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Steps involved in data preprocesing :\n",
    "\n",
    "# 1. Removing special characters,unwanted numericals \n",
    "# 2. Normalize the case(lower)\n",
    "# 3. Word Tokenization\n",
    "# 4. Removing stop words\n",
    "# 5. Stemming or Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b295c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rjsek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Remove specific words from the NLTK stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update({'Hii', 'it', 'Product', 'Shuttle', 'hii', 'flipkart', 'flipkartread', 'product', 'productread', 'read', 'goodread','shuttle', 'Readmore'})\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    # Removes special characters\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", data)\n",
    "    \n",
    "    # Converts words to lowercase\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    # Removes the stop words\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "    \n",
    "    # Applying lemmatization\n",
    "    sentence = [Lemmatization.lemmatize(word) for word in sentence]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    sentence = \" \".join(sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Apply preprocess function to the 'Review text' column in the Badminton dataset\n",
    "Badminton['Cleaned Review Text'] = Badminton['Review text'].apply(preprocess)\n",
    "\n",
    "# Display the modified dataset\n",
    "# print(Badminton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ca181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41729d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying preprocesing on train_data\n",
    "\n",
    "x_train= x_train.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23740faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3c251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f399c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying preprocessing on test_data\n",
    "\n",
    "x_test = x_test.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8404e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a1e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words / Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f65b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 315 ms\n",
      "(6410, 2602)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectorizer\n",
    "vect = CountVectorizer(preprocessor=preprocess)\n",
    "\n",
    "# use it to extract features from training data\n",
    "%time x_train_dtm = vect.fit_transform(x_train)\n",
    "\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d32bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5a3c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc53608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 244 ms\n",
      "(6410, 2602)\n"
     ]
    }
   ],
   "source": [
    "# Import TF-IDF vectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate a TF-IDF vectorizer\n",
    "tfidf_vect = TfidfVectorizer(preprocessor=preprocess)\n",
    "\n",
    "# Use it to extract features from training data\n",
    "%time x_train_tfidf = tfidf_vect.fit_transform(x_train)\n",
    "\n",
    "print(x_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7102922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe276331-7d88-45c9-8656-d937096cf192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c89da7ad-d3ca-4e5f-a040-d9034e1ca203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the data in a DataFrame named \"Badminton\"\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'cleaned_data.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "Badminton.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Data has been successfully saved to\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb9c73-18f4-4020-ab03-7e5b320cf463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67960a0e-4d61-4934-bca5-840ef8c4e6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce7df097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from joblib import Memory\n",
    "\n",
    "# Define a memory object to cache intermediate results\n",
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "# Define pipelines for selected models with both CountVectorizer and TfidfVectorizer\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', FeatureUnion([\n",
    "            ('count_vectorizer', CountVectorizer()),\n",
    "            ('tfidf_vectorizer', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('vectorization', FeatureUnion([\n",
    "            ('count_vectorizer', CountVectorizer()),\n",
    "            ('tfidf_vectorizer', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ], memory=memory),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', FeatureUnion([\n",
    "            ('count_vectorizer', CountVectorizer()),\n",
    "            ('tfidf_vectorizer', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    'svm': Pipeline([\n",
    "        ('vectorization', FeatureUnion([\n",
    "            ('count_vectorizer', CountVectorizer()),\n",
    "            ('tfidf_vectorizer', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('classifier', SVC())\n",
    "    ], memory=memory),\n",
    "    'random_forest': Pipeline([\n",
    "        ('vectorization', FeatureUnion([\n",
    "            ('count_vectorizer', CountVectorizer()),\n",
    "            ('tfidf_vectorizer', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ], memory=memory),\n",
    "    'knn': Pipeline([\n",
    "        ('vectorization', FeatureUnion([\n",
    "            ('count_vectorizer', CountVectorizer()),\n",
    "            ('tfidf_vectorizer', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ], memory=memory)\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': {\n",
    "        'vectorization__count_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'vectorization__tfidf_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'classifier__alpha': [1, 10]\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'vectorization__count_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'vectorization__tfidf_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'classifier__max_depth': [None, 5, 10]\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'vectorization__count_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'vectorization__tfidf_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l2']\n",
    "    },\n",
    "    'svm': {\n",
    "        'vectorization__count_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'vectorization__tfidf_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'vectorization__count_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'vectorization__tfidf_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 5, 10]\n",
    "    },\n",
    "    'knn': {\n",
    "        'vectorization__count_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'vectorization__tfidf_vectorizer__max_features': [1000, 2000, 5000],\n",
    "        'classifier__n_neighbors': [i for i in range(3, 21, 2)],  # Experiment with different values of n_neighbors\n",
    "        'classifier__p': [1, 2, 3]\n",
    "    }\n",
    "}\n",
    "\n",
    "# # Perform GridSearchCV for each algorithm\n",
    "# best_models = {}\n",
    "\n",
    "# for algo in pipelines.keys():\n",
    "#     print(\"*\" * 10, algo, \"*\" * 10)\n",
    "#     grid_search = GridSearchCV(estimator=pipelines[algo],\n",
    "#                                param_grid=param_grids[algo],\n",
    "#                                cv=5,\n",
    "#                                scoring='f1',\n",
    "#                                return_train_score=True,\n",
    "#                                verbose=1)\n",
    "#     grid_search.fit(x_train, y_train)\n",
    "#     best_models[algo] = grid_search.best_estimator_\n",
    "#     y_pred = grid_search.best_estimator_.predict(x_test)\n",
    "#     f1 = f1_score(y_test, y_pred, pos_label='Positive', average='weighted')\n",
    "#     print('F1 Score on Test Data:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c442c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72be4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2ad75c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rjsek\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6906b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b7d0edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.11.3-py3-none-any.whl (19.7 MB)\n",
      "     --------------------------------------- 19.7/19.7 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting waitress<4\n",
      "  Downloading waitress-3.0.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.7/56.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (6.0)\n",
      "Collecting querystring-parser<2\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (2.2.2)\n",
      "Collecting gitpython<4,>=3.1.9\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "     -------------------------------------- 195.4/195.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting alembic!=1.10.0,<2\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.4/233.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting docker<8,>=4.0.0\n",
      "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "     -------------------------------------- 147.6/147.6 kB 9.2 MB/s eta 0:00:00\n",
      "Collecting pyarrow<16,>=4.0.0\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-win_amd64.whl (24.8 MB)\n",
      "     --------------------------------------- 24.8/24.8 MB 11.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (2.0.0)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (1.23.5)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (1.4.39)\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (4.11.3)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (1.5.3)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (3.7.0)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.2/41.2 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (1.2.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (3.4.1)\n",
      "Collecting graphene<4\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "     -------------------------------------- 128.2/128.2 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging<24 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (22.0)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (1.10.0)\n",
      "Requirement already satisfied: pytz<2025 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (2022.7)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from mlflow) (2.31.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.7/78.7 kB 877.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (1.26.14)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.2.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.0.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     -------------------------------------- 62.7/62.7 kB 672.8 kB/s eta 0:00:00\n",
      "Collecting aniso8601<10,>=8\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "     -------------------------------------- 52.8/52.8 kB 674.8 kB/s eta 0:00:00\n",
      "Collecting graphql-core<3.3,>=3.1\n",
      "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
      "     -------------------------------------- 202.9/202.9 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting graphql-relay<3.3,>=3.1\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (1.1.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: aniso8601, waitress, sqlparse, smmap, querystring-parser, pyarrow, protobuf, Mako, graphql-core, graphql-relay, gitdb, docker, alembic, graphene, gitpython, mlflow\n",
      "Successfully installed Mako-1.3.2 alembic-1.13.1 aniso8601-9.0.1 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.42 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 mlflow-2.11.3 protobuf-4.25.3 pyarrow-15.0.2 querystring-parser-1.2.4 smmap-5.0.1 sqlparse-0.4.4 waitress-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041da64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd5481ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Logging Experiment Run using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Import MLFlow and set the experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a243130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:21:40 INFO mlflow.tracking.fluent: Experiment with name 'Flipkart_Sentiment_Prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/rjsek/OneDrive/Desktop/ML%20Flow/mlruns/818060538876186520', creation_time=1711291900972, experiment_id='818060538876186520', last_update_time=1711291900972, lifecycle_stage='active', name='Flipkart_Sentiment_Prediction', tags={}>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Flipkart_Sentiment_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd4cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b24c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Start the auto logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc0905aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Initialize the auto logger\n",
    "# max_tuning_runs=None will make sure that all the runs are recorded.\n",
    "# By default top 5 runs will be recorded for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd50f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Start the experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ecd8e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 19:56:21 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:05:34 WARNING mlflow.sklearn.utils: BaseSearchCV.score failed. The 'training_score' metric will not be recorded. Scoring error: pos_label=1 is not a valid label. It should be one of ['Negative', 'Positive']\n",
      "2024/03/24 20:05:43 INFO mlflow.sklearn.utils: Logging the 5 best runs, 238 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217951f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93f5c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:21:46 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:22:06 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12 s\n",
      "Wall time: 19.7 s\n",
      "Train Score:  0.9232449297971919\n",
      "Test Score:  0.9238927011852776\n",
      "\n",
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:22:49 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 34.9 s\n",
      "Wall time: 42.8 s\n",
      "Train Score:  0.9141965678627146\n",
      "Test Score:  0.9114160948222083\n",
      "\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:23:18 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 35.7 s\n",
      "Wall time: 29.4 s\n",
      "Train Score:  0.9205928237129484\n",
      "Test Score:  0.916406737367436\n",
      "\n",
      "********** svm **********\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "CPU times: total: 4min 3s\n",
      "Wall time: 4min 17s\n",
      "Train Score:  0.9177847113884555\n",
      "Test Score:  0.9139114160948222\n",
      "\n",
      "********** random_forest **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:27:36 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "CPU times: total: 10min 42s\n",
      "Wall time: 11min 11s\n",
      "Train Score:  0.9205928237129484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 20:38:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.9151590767311292\n",
      "\n",
      "********** knn **********\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "CPU times: total: 1h 29min 30s\n",
      "Wall time: 9min 21s\n",
      "Train Score:  0.909984399375975\n",
      "Test Score:  0.9107922645040549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(x_train, y_train)\n",
    "        \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(x_test, y_test))\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc0abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597ea57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d79ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d37b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe290ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848fea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba0ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76223d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1fa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac50e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e51f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e970ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e51275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b352c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673cfdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c10573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7df80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ee1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b677af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c517d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca693e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54342dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9298f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be4e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490c036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b72cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c1359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b05ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebea02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562e115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e081e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd7d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2f5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfa1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55506a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e728390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb37c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f495f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819ea37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95301b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a944f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ac730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177740b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0090bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45597fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48466b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b63e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfa17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4498cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf3285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46c84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71978c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21a220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7409d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1a876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576bf95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919b364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbbd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47a694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba0139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc524e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4f1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cc000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1985b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d62951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fcf79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7102f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de929b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a3cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11ba38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ed580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15391fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672691f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6065072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5076b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbe02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d3996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4f127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69b273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484cf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e069112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1ad38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86a436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a284b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae877a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d67da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054a342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54853e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e1880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cd11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497de59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96016018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e672416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37456f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257866d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6900c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbeb25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef7663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c5cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
